{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See tutorial materials here:  https://scipy2018.scipy.org/ehome/299...\n",
    "\n",
    "See the full SciPy 2018 playlist here: https://www.youtube.com/playlist?list...\n",
    "\n",
    "\n",
    "For anyone interested, you can find the materials at https://github.com/martindurant/dask-tutorial-scipy-2018 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package fsspec:\n",
      "\n",
      "NAME\n",
      "    fsspec\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _version\n",
      "    caching\n",
      "    compression\n",
      "    conftest\n",
      "    core\n",
      "    dircache\n",
      "    fuse\n",
      "    implementations (package)\n",
      "    mapping\n",
      "    registry\n",
      "    spec\n",
      "    transaction\n",
      "    utils\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        fsspec.spec.AbstractFileSystem\n",
      "    collections.abc.MutableMapping(collections.abc.Mapping)\n",
      "        fsspec.mapping.FSMap\n",
      "    \n",
      "    class AbstractFileSystem(builtins.object)\n",
      "     |  AbstractFileSystem(*args, **kwargs)\n",
      "     |  \n",
      "     |  An abstract super-class for pythonic file-systems\n",
      "     |  \n",
      "     |  Implementations are expected to be compatible with or, better, subclass\n",
      "     |  from here.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __dask_tokenize__(self)\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, *args, **storage_options)\n",
      "     |      Create and configure file-system instance\n",
      "     |      \n",
      "     |      Instances may be cachable, so if similar enough arguments are seen\n",
      "     |      a new instance is not required. The token attribute exists to allow\n",
      "     |      implementations to cache instances if they wish.\n",
      "     |      \n",
      "     |      A reasonable default should be provided if there are no arguments.\n",
      "     |      \n",
      "     |      Subclasses should call this method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      use_listings_cache, listings_expiry_time, max_paths:\n",
      "     |          passed to ``DirCache``, if the implementation supports\n",
      "     |          directory listing caching. Pass use_listings_cache=False\n",
      "     |          to disable such caching.\n",
      "     |      skip_instance_cache: bool\n",
      "     |          If this is a cachable implementation, pass True here to force\n",
      "     |          creating a new instance even if a matching instance exists, and prevent\n",
      "     |          storing this instance.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  cat(self, path)\n",
      "     |      Get the content of a file\n",
      "     |  \n",
      "     |  checksum(self, path)\n",
      "     |      Unique value for current version of file\n",
      "     |      \n",
      "     |      If the checksum is the same from one moment to another, the contents\n",
      "     |      are guaranteed to be the same. If the checksum changes, the contents\n",
      "     |      *might* have changed.\n",
      "     |      \n",
      "     |      This should normally be overridden; default will probably capture\n",
      "     |      creation/modification timestamp (which would be good) or maybe\n",
      "     |      access timestamp (which would be bad)\n",
      "     |  \n",
      "     |  copy(self, path1, path2, **kwargs)\n",
      "     |      Copy within two locations in the filesystem\n",
      "     |  \n",
      "     |  cp(self, path1, path2, **kwargs)\n",
      "     |      Alias of :ref:`FilesystemSpec.copy`.\n",
      "     |  \n",
      "     |  created(self, path)\n",
      "     |      Return the created timestamp of a file as a datetime.datetime\n",
      "     |  \n",
      "     |  delete(self, path, recursive=False, maxdepth=None)\n",
      "     |      Alias of :ref:`FilesystemSpec.rm`.\n",
      "     |  \n",
      "     |  disk_usage(self, path, total=True, maxdepth=None, **kwargs)\n",
      "     |      Alias of :ref:`FilesystemSpec.du`.\n",
      "     |  \n",
      "     |  download(self, rpath, lpath, recursive=False, **kwargs)\n",
      "     |      Alias of :ref:`FilesystemSpec.get`.\n",
      "     |  \n",
      "     |  du(self, path, total=True, maxdepth=None, **kwargs)\n",
      "     |      Space used by files within a path\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path: str\n",
      "     |      total: bool\n",
      "     |          whether to sum all the file sizes\n",
      "     |      maxdepth: int or None\n",
      "     |          maximum number of directory levels to descend, None for unlimited.\n",
      "     |      kwargs: passed to ``ls``\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Dict of {fn: size} if total=False, or int otherwise, where numbers\n",
      "     |      refer to bytes used.\n",
      "     |  \n",
      "     |  end_transaction(self)\n",
      "     |      Finish write transaction, non-context version\n",
      "     |  \n",
      "     |  exists(self, path)\n",
      "     |      Is there a file at the given path\n",
      "     |  \n",
      "     |  find(self, path, maxdepth=None, withdirs=False, **kwargs)\n",
      "     |      List all files below path.\n",
      "     |      \n",
      "     |      Like posix ``find`` command without conditions\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path : str\n",
      "     |      maxdepth: int or None\n",
      "     |          If not None, the maximum number of levels to descend\n",
      "     |      withdirs: bool\n",
      "     |          Whether to include directory paths in the output. This is True\n",
      "     |          when used by glob, but users usually only want files.\n",
      "     |      kwargs are passed to ``ls``.\n",
      "     |  \n",
      "     |  get(self, rpath, lpath, recursive=False, **kwargs)\n",
      "     |      Copy file to local.\n",
      "     |      \n",
      "     |      Possible extension: maybe should be able to copy to any file-system\n",
      "     |      (streaming through local).\n",
      "     |  \n",
      "     |  get_mapper(self, root, check=False, create=False)\n",
      "     |      Create key/value store based on this file-system\n",
      "     |      \n",
      "     |      Makes a MutibleMapping interface to the FS at the given root path.\n",
      "     |      See ``fsspec.mapping.FSMap`` for further details.\n",
      "     |  \n",
      "     |  glob(self, path, **kwargs)\n",
      "     |      Find files by glob-matching.\n",
      "     |      \n",
      "     |      If the path ends with '/' and does not contain \"*\", it is essentially\n",
      "     |      the same as ``ls(path)``, returning only files.\n",
      "     |      \n",
      "     |      We support ``\"**\"``,\n",
      "     |      ``\"?\"`` and ``\"[..]\"``.\n",
      "     |      \n",
      "     |      kwargs are passed to ``ls``.\n",
      "     |  \n",
      "     |  head(self, path, size=1024)\n",
      "     |      Get the first ``size`` bytes from file\n",
      "     |  \n",
      "     |  info(self, path, **kwargs)\n",
      "     |      Give details of entry at path\n",
      "     |      \n",
      "     |      Returns a single dictionary, with exactly the same information as ``ls``\n",
      "     |      would with ``detail=True``.\n",
      "     |      \n",
      "     |      The default implementation should calls ls and could be overridden by a\n",
      "     |      shortcut. kwargs are passed on to ```ls()``.\n",
      "     |      \n",
      "     |      Some file systems might not be able to measure the file's size, in\n",
      "     |      which case, the returned dict will include ``'size': None``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      dict with keys: name (full path in the FS), size (in bytes), type (file,\n",
      "     |      directory, or something else) and other FS-specific keys.\n",
      "     |  \n",
      "     |  invalidate_cache(self, path=None)\n",
      "     |      Discard any cached directory information\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path: string or None\n",
      "     |          If None, clear all listings cached else listings at or under given\n",
      "     |          path.\n",
      "     |  \n",
      "     |  isdir(self, path)\n",
      "     |      Is this entry directory-like?\n",
      "     |  \n",
      "     |  isfile(self, path)\n",
      "     |      Is this entry file-like?\n",
      "     |  \n",
      "     |  listdir(self, path, detail=True, **kwargs)\n",
      "     |      Alias of :ref:`FilesystemSpec.ls`.\n",
      "     |  \n",
      "     |  ls(self, path, detail=True, **kwargs)\n",
      "     |      List objects at path.\n",
      "     |      \n",
      "     |      This should include subdirectories and files at that location. The\n",
      "     |      difference between a file and a directory must be clear when details\n",
      "     |      are requested.\n",
      "     |      \n",
      "     |      The specific keys, or perhaps a FileInfo class, or similar, is TBD,\n",
      "     |      but must be consistent across implementations.\n",
      "     |      Must include:\n",
      "     |      - full path to the entry (without protocol)\n",
      "     |      - size of the entry, in bytes. If the value cannot be determined, will\n",
      "     |        be ``None``.\n",
      "     |      - type of entry, \"file\", \"directory\" or other\n",
      "     |      \n",
      "     |      Additional information\n",
      "     |      may be present, aproriate to the file-system, e.g., generation,\n",
      "     |      checksum, etc.\n",
      "     |      \n",
      "     |      May use refresh=True|False to allow use of self._ls_from_cache to\n",
      "     |      check for a saved listing and avoid calling the backend. This would be\n",
      "     |      common where listing may be expensive.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path: str\n",
      "     |      detail: bool\n",
      "     |          if True, gives a list of dictionaries, where each is the same as\n",
      "     |          the result of ``info(path)``. If False, gives a list of paths\n",
      "     |          (str).\n",
      "     |      kwargs: may have additional backend-specific options, such as version\n",
      "     |          information\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      List of strings if detail is False, or list of directory information\n",
      "     |      dicts if detail is True.\n",
      "     |  \n",
      "     |  makedir(self, path, create_parents=True, **kwargs)\n",
      "     |      Alias of :ref:`FilesystemSpec.mkdir`.\n",
      "     |  \n",
      "     |  makedirs(self, path, exist_ok=False)\n",
      "     |      Recursively make directories\n",
      "     |      \n",
      "     |      Creates directory at path and any intervening required directories.\n",
      "     |      Raises exception if, for instance, the path already exists but is a\n",
      "     |      file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path: str\n",
      "     |          leaf directory name\n",
      "     |      exist_ok: bool (False)\n",
      "     |          If True, will error if the target already exists\n",
      "     |  \n",
      "     |  mkdir(self, path, create_parents=True, **kwargs)\n",
      "     |      Create directory entry at path\n",
      "     |      \n",
      "     |      For systems that don't have true directories, may create an for\n",
      "     |      this instance only and not touch the real filesystem\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path: str\n",
      "     |          location\n",
      "     |      create_parents: bool\n",
      "     |          if True, this is equivalent to ``makedirs``\n",
      "     |      kwargs:\n",
      "     |          may be permissions, etc.\n",
      "     |  \n",
      "     |  mkdirs(self, path, exist_ok=False)\n",
      "     |      Alias of :ref:`FilesystemSpec.makedirs`.\n",
      "     |  \n",
      "     |  modified(self, path)\n",
      "     |      Return the modified timestamp of a file as a datetime.datetime\n",
      "     |  \n",
      "     |  move(self, path1, path2, **kwargs)\n",
      "     |      Alias of :ref:`FilesystemSpec.mv`.\n",
      "     |  \n",
      "     |  mv(self, path1, path2, **kwargs)\n",
      "     |      Move file from one location to another\n",
      "     |  \n",
      "     |  open(self, path, mode='rb', block_size=None, cache_options=None, **kwargs)\n",
      "     |      Return a file-like object from the filesystem\n",
      "     |      \n",
      "     |      The resultant instance must function correctly in a context ``with``\n",
      "     |      block.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path: str\n",
      "     |          Target file\n",
      "     |      mode: str like 'rb', 'w'\n",
      "     |          See builtin ``open()``\n",
      "     |      block_size: int\n",
      "     |          Some indication of buffering - this is a value in bytes\n",
      "     |      cache_options : dict, optional\n",
      "     |          Extra arguments to pass through to the cache.\n",
      "     |      encoding, errors, newline: passed on to TextIOWrapper for text mode\n",
      "     |  \n",
      "     |  put(self, lpath, rpath, recursive=False, **kwargs)\n",
      "     |      Upload file from local\n",
      "     |  \n",
      "     |  read_block(self, fn, offset, length, delimiter=None)\n",
      "     |      Read a block of bytes from\n",
      "     |      \n",
      "     |      Starting at ``offset`` of the file, read ``length`` bytes.  If\n",
      "     |      ``delimiter`` is set then we ensure that the read starts and stops at\n",
      "     |      delimiter boundaries that follow the locations ``offset`` and ``offset\n",
      "     |      + length``.  If ``offset`` is zero then we start at zero.  The\n",
      "     |      bytestring returned WILL include the end delimiter string.\n",
      "     |      \n",
      "     |      If offset+length is beyond the eof, reads to eof.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fn: string\n",
      "     |          Path to filename\n",
      "     |      offset: int\n",
      "     |          Byte offset to start read\n",
      "     |      length: int\n",
      "     |          Number of bytes to read\n",
      "     |      delimiter: bytes (optional)\n",
      "     |          Ensure reading starts and stops at delimiter bytestring\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> fs.read_block('data/file.csv', 0, 13)  # doctest: +SKIP\n",
      "     |      b'Alice, 100\\nBo'\n",
      "     |      >>> fs.read_block('data/file.csv', 0, 13, delimiter=b'\\n')  # doctest: +SKIP\n",
      "     |      b'Alice, 100\\nBob, 200\\n'\n",
      "     |      \n",
      "     |      Use ``length=None`` to read to the end of the file.\n",
      "     |      >>> fs.read_block('data/file.csv', 0, None, delimiter=b'\\n')  # doctest: +SKIP\n",
      "     |      b'Alice, 100\\nBob, 200\\nCharlie, 300'\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      utils.read_block\n",
      "     |  \n",
      "     |  rename(self, path1, path2, **kwargs)\n",
      "     |      Alias of :ref:`FilesystemSpec.mv`.\n",
      "     |  \n",
      "     |  rm(self, path, recursive=False, maxdepth=None)\n",
      "     |      Delete files.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path: str or list of str\n",
      "     |          File(s) to delete.\n",
      "     |      recursive: bool\n",
      "     |          If file(s) are directories, recursively delete contents and then\n",
      "     |          also remove the directory\n",
      "     |      maxdepth: int or None\n",
      "     |          Depth to pass to walk for finding files to delete, if recursive.\n",
      "     |          If None, there will be no limit and infinite recursion may be\n",
      "     |          possible.\n",
      "     |  \n",
      "     |  rmdir(self, path)\n",
      "     |      Remove a directory, if empty\n",
      "     |  \n",
      "     |  size(self, path)\n",
      "     |      Size in bytes of file\n",
      "     |  \n",
      "     |  start_transaction(self)\n",
      "     |      Begin write transaction for deferring files, non-context version\n",
      "     |  \n",
      "     |  stat(self, path, **kwargs)\n",
      "     |      Alias of :ref:`FilesystemSpec.info`.\n",
      "     |  \n",
      "     |  tail(self, path, size=1024)\n",
      "     |      Get the last ``size`` bytes from file\n",
      "     |  \n",
      "     |  to_json(self)\n",
      "     |      JSON representation of this filesystem instance\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      str: JSON structure with keys cls (the python location of this class),\n",
      "     |          protocol (text name of this class's protocol, first one in case of\n",
      "     |          multiple), args (positional args, usually empty), and all other\n",
      "     |          kwargs as their own keys.\n",
      "     |  \n",
      "     |  touch(self, path, truncate=True, **kwargs)\n",
      "     |      Create empty file, or update timestamp\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path: str\n",
      "     |          file location\n",
      "     |      truncate: bool\n",
      "     |          If True, always set file size to 0; if False, update timestamp and\n",
      "     |          leave file unchanged, if backend allows this\n",
      "     |  \n",
      "     |  ukey(self, path)\n",
      "     |      Hash of file properties, to tell if it has changed\n",
      "     |  \n",
      "     |  upload(self, lpath, rpath, recursive=False, **kwargs)\n",
      "     |      Alias of :ref:`FilesystemSpec.put`.\n",
      "     |  \n",
      "     |  walk(self, path, maxdepth=None, **kwargs)\n",
      "     |      Return all files belows path\n",
      "     |      \n",
      "     |      List all files, recursing into subdirectories; output is iterator-style,\n",
      "     |      like ``os.walk()``. For a simple list of files, ``find()`` is available.\n",
      "     |      \n",
      "     |      Note that the \"files\" outputted will include anything that is not\n",
      "     |      a directory, such as links.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      path: str\n",
      "     |          Root to recurse into\n",
      "     |      maxdepth: int\n",
      "     |          Maximum recursion depth. None means limitless, but not recommended\n",
      "     |          on link-based file-systems.\n",
      "     |      kwargs: passed to ``ls``\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  clear_instance_cache() from fsspec.spec._Cached\n",
      "     |      Clear the cache of filesystem instances.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Unless overridden by setting the ``cachable`` class attribute to False,\n",
      "     |      the filesystem class stores a reference to newly created instances. This\n",
      "     |      prevents Python's normal rules around garbage collection from working,\n",
      "     |      since the instances refcount will not drop to zero until\n",
      "     |      ``clear_instance_cache`` is called.\n",
      "     |  \n",
      "     |  current() from fsspec.spec._Cached\n",
      "     |      Return the most recently created FileSystem\n",
      "     |      \n",
      "     |      If no instance has been created, then create one with defaults\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_json(blob)\n",
      "     |      Recreate a filesystem instance from JSON representation\n",
      "     |      \n",
      "     |      See ``.to_json()`` for the expected structure of the input\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      blob: str\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      file system instance, not necessarily of this particular class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  transaction\n",
      "     |      A context within which files are committed together upon exit\n",
      "     |      \n",
      "     |      Requires the file class to implement `.commit()` and `.discard()`\n",
      "     |      for the normal and exception cases.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  blocksize = 4194304\n",
      "     |  \n",
      "     |  cachable = True\n",
      "     |  \n",
      "     |  protocol = 'abstract'\n",
      "     |  \n",
      "     |  root_marker = ''\n",
      "     |  \n",
      "     |  sep = '/'\n",
      "    \n",
      "    class FSMap(collections.abc.MutableMapping)\n",
      "     |  FSMap(root, fs, check=False, create=False)\n",
      "     |  \n",
      "     |  Wrap a FileSystem instance as a mutable wrapping.\n",
      "     |  \n",
      "     |  The keys of the mapping become files under the given root, and the\n",
      "     |  values (which must be bytes) the contents of those files.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  root: string\n",
      "     |      prefix for all the files\n",
      "     |  fs: FileSystem instance\n",
      "     |  check: bool (=True)\n",
      "     |      performs a touch at the location, to check for write access.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> fs = FileSystem(**parameters) # doctest: +SKIP\n",
      "     |  >>> d = FSMap('my-data/path/', fs) # doctest: +SKIP\n",
      "     |  or, more likely\n",
      "     |  >>> d = fs.get_mapper('my-data/path/')\n",
      "     |  \n",
      "     |  >>> d['loc1'] = b'Hello World' # doctest: +SKIP\n",
      "     |  >>> list(d.keys()) # doctest: +SKIP\n",
      "     |  ['loc1']\n",
      "     |  >>> d['loc1'] # doctest: +SKIP\n",
      "     |  b'Hello World'\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FSMap\n",
      "     |      collections.abc.MutableMapping\n",
      "     |      collections.abc.Mapping\n",
      "     |      collections.abc.Collection\n",
      "     |      collections.abc.Sized\n",
      "     |      collections.abc.Iterable\n",
      "     |      collections.abc.Container\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __contains__(self, key)\n",
      "     |      Does key exist in mapping?\n",
      "     |  \n",
      "     |  __delitem__(self, key)\n",
      "     |      Remove key\n",
      "     |  \n",
      "     |  __getitem__(self, key, default=None)\n",
      "     |      Retrieve data\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Mapping should be pickleable\n",
      "     |  \n",
      "     |  __init__(self, root, fs, check=False, create=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value)\n",
      "     |      Store value in key\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  clear(self)\n",
      "     |      Remove all keys below root - empties out mapping\n",
      "     |  \n",
      "     |  pop(self, key, default=None)\n",
      "     |      D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n",
      "     |      If key is not found, d is returned if given, otherwise KeyError is raised.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.MutableMapping:\n",
      "     |  \n",
      "     |  popitem(self)\n",
      "     |      D.popitem() -> (k, v), remove and return some (key, value) pair\n",
      "     |      as a 2-tuple; but raise KeyError if D is empty.\n",
      "     |  \n",
      "     |  setdefault(self, key, default=None)\n",
      "     |      D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D\n",
      "     |  \n",
      "     |  update(*args, **kwds)\n",
      "     |      D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.\n",
      "     |      If E present and has a .keys() method, does:     for k in E: D[k] = E[k]\n",
      "     |      If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v\n",
      "     |      In either case, this is followed by: for k, v in F.items(): D[k] = v\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  get(self, key, default=None)\n",
      "     |      D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.\n",
      "     |  \n",
      "     |  items(self)\n",
      "     |      D.items() -> a set-like object providing a view on D's items\n",
      "     |  \n",
      "     |  keys(self)\n",
      "     |      D.keys() -> a set-like object providing a view on D's keys\n",
      "     |  \n",
      "     |  values(self)\n",
      "     |      D.values() -> an object providing a view on D's values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from collections.abc.Mapping:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __reversed__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from collections.abc.Collection:\n",
      "     |  \n",
      "     |  __subclasshook__(C) from abc.ABCMeta\n",
      "     |      Abstract classes can override this to customize issubclass().\n",
      "     |      \n",
      "     |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      "     |      It should return True, False or NotImplemented.  If it returns\n",
      "     |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      "     |      overrides the normal algorithm (and the outcome is cached).\n",
      "\n",
      "FUNCTIONS\n",
      "    filesystem(protocol, **storage_options)\n",
      "        Instantiate filesystems for given protocol and arguments\n",
      "        \n",
      "        ``storage_options`` are specific to the protocol being chosen, and are\n",
      "        passed directly to the class.\n",
      "    \n",
      "    get_filesystem_class(protocol)\n",
      "        Fetch named protocol implementation from the registry\n",
      "        \n",
      "        The dict ``known_implementations`` maps protocol names to the locations\n",
      "        of classes implementing the corresponding file-system. When used for the\n",
      "        first time, appropriate imports will happen and the class will be placed in\n",
      "        the registry. All subsequent calls will fetch directly from the registry.\n",
      "        \n",
      "        Some protocol implementations require additional dependencies, and so the\n",
      "        import may fail. In this case, the string in the \"err\" field of the\n",
      "        ``known_implementations`` will be given as the error message.\n",
      "    \n",
      "    get_fs_token_paths(urlpath, mode='rb', num=1, name_function=None, storage_options=None, protocol=None)\n",
      "        Filesystem, deterministic token, and paths from a urlpath and options.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        urlpath: string or iterable\n",
      "            Absolute or relative filepath, URL (may include protocols like\n",
      "            ``s3://``), or globstring pointing to data.\n",
      "        mode: str, optional\n",
      "            Mode in which to open files.\n",
      "        num: int, optional\n",
      "            If opening in writing mode, number of files we expect to create.\n",
      "        name_function: callable, optional\n",
      "            If opening in writing mode, this callable is used to generate path\n",
      "            names. Names are generated for each partition by\n",
      "            ``urlpath.replace('*', name_function(partition_index))``.\n",
      "        storage_options: dict, optional\n",
      "            Additional keywords to pass to the filesystem class.\n",
      "        protocol: str or None\n",
      "            To override the protocol specifier in the URL\n",
      "    \n",
      "    get_mapper(url, check=False, create=False, **kwargs)\n",
      "        Create key-value interface for given URL and options\n",
      "        \n",
      "        The URL will be of the form \"protocol://location\" and point to the root\n",
      "        of the mapper required. All keys will be file-names below this location,\n",
      "        and their values the contents of each key.\n",
      "        \n",
      "        Also accepts compound URLs like zip::s3://bucket/file.zip , see ``fsspec.open``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        url: str\n",
      "            Root URL of mapping\n",
      "        check: bool\n",
      "            Whether to attempt to read from the location before instantiation, to\n",
      "            check that the mapping does exist\n",
      "        create: bool\n",
      "            Whether to make the directory corresponding to the root before\n",
      "            instantiating\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ``FSMap`` instance, the dict-like key-value store.\n",
      "    \n",
      "    open(urlpath, mode='rb', compression=None, encoding='utf8', errors=None, protocol=None, newline=None, **kwargs)\n",
      "        Given a path or paths, return one ``OpenFile`` object.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        urlpath: string or list\n",
      "            Absolute or relative filepath. Prefix with a protocol like ``s3://``\n",
      "            to read from alternative filesystems. Should not include glob\n",
      "            character(s).\n",
      "        mode: 'rb', 'wt', etc.\n",
      "        compression: string\n",
      "            Compression to use.  See ``dask.bytes.compression.files`` for options.\n",
      "        encoding: str\n",
      "            For text mode only\n",
      "        errors: None or str\n",
      "            Passed to TextIOWrapper in text mode\n",
      "        protocol: str or None\n",
      "            If given, overrides the protocol found in the URL.\n",
      "        newline: bytes or None\n",
      "            Used for line terminator in text mode. If None, uses system default;\n",
      "            if blank, uses no translation.\n",
      "        **kwargs: dict\n",
      "            Extra options that make sense to a particular storage connection, e.g.\n",
      "            host, port, username, password, etc.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> openfile = open('2015-01-01.csv')  # doctest: +SKIP\n",
      "        >>> openfile = open(\n",
      "        ...     's3://bucket/2015-01-01.csv.gz',\n",
      "        ...     compression='gzip'\n",
      "        ... )  # doctest: +SKIP\n",
      "        >>> with openfile as f:\n",
      "        ...     df = pd.read_csv(f)  # doctest: +SKIP\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ``OpenFile`` object.\n",
      "    \n",
      "    open_files(urlpath, mode='rb', compression=None, encoding='utf8', errors=None, name_function=None, num=1, protocol=None, newline=None, auto_mkdir=True, **kwargs)\n",
      "        Given a path or paths, return a list of ``OpenFile`` objects.\n",
      "        \n",
      "        For writing, a str path must contain the \"*\" character, which will be filled\n",
      "        in by increasing numbers, e.g., \"part*\" ->  \"part1\", \"part2\" if num=2.\n",
      "        \n",
      "        For either reading or writing, can instead provide explicit list of paths.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        urlpath: string or list\n",
      "            Absolute or relative filepath(s). Prefix with a protocol like ``s3://``\n",
      "            to read from alternative filesystems. To read from multiple files you\n",
      "            can pass a globstring or a list of paths, with the caveat that they\n",
      "            must all have the same protocol.\n",
      "        mode: 'rb', 'wt', etc.\n",
      "        compression: string\n",
      "            Compression to use.  See ``dask.bytes.compression.files`` for options.\n",
      "        encoding: str\n",
      "            For text mode only\n",
      "        errors: None or str\n",
      "            Passed to TextIOWrapper in text mode\n",
      "        name_function: function or None\n",
      "            if opening a set of files for writing, those files do not yet exist,\n",
      "            so we need to generate their names by formatting the urlpath for\n",
      "            each sequence number\n",
      "        num: int [1]\n",
      "            if writing mode, number of files we expect to create (passed to\n",
      "            name+function)\n",
      "        protocol: str or None\n",
      "            If given, overrides the protocol found in the URL.\n",
      "        newline: bytes or None\n",
      "            Used for line terminator in text mode. If None, uses system default;\n",
      "            if blank, uses no translation.\n",
      "        auto_mkdir: bool (True)\n",
      "            If in write mode, this will ensure the target directory exists before\n",
      "            writing, by calling ``fs.mkdirs(exist_ok=True)``.\n",
      "        **kwargs: dict\n",
      "            Extra options that make sense to a particular storage connection, e.g.\n",
      "            host, port, username, password, etc.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> files = open_files('2015-*-*.csv')  # doctest: +SKIP\n",
      "        >>> files = open_files(\n",
      "        ...     's3://bucket/2015-*-*.csv.gz', compression='gzip'\n",
      "        ... )  # doctest: +SKIP\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        List of ``OpenFile`` objects.\n",
      "    \n",
      "    open_local(url, mode='rb', **storage_options)\n",
      "        Open file(s) which can be resolved to local\n",
      "        \n",
      "        For files which either are local, or get downloaded upon open\n",
      "        (e.g., by file caching)\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        url: str or list(str)\n",
      "        mode: str\n",
      "            Must be read mode\n",
      "        storage_options:\n",
      "            passed on to FS for or used by open_files (e.g., compression)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['AbstractFileSystem', 'FSMap', 'filesystem', 'get_filesyste...\n",
      "    registry = {}\n",
      "\n",
      "VERSION\n",
      "    0.7.3\n",
      "\n",
      "FILE\n",
      "    /opt/tljh/user/lib/python3.7/site-packages/fsspec/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help (fsspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dev-et-data/01drop',\n",
       " 'dev-et-data/NDVI_filled',\n",
       " 'dev-et-data/Readme-bucket.md',\n",
       " 'dev-et-data/compressed',\n",
       " 'dev-et-data/etasw_2014',\n",
       " 'dev-et-data/etasw_2015',\n",
       " 'dev-et-data/greg_outputs',\n",
       " 'dev-et-data/level-1',\n",
       " 'dev-et-data/steff_2014',\n",
       " 'dev-et-data/steff_2015',\n",
       " 'dev-et-data/tony.txt',\n",
       " 'dev-et-data/v1DRB_outputs']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fsspec\n",
    "fs = fsspec.filesystem('s3', anon=False, requester_pays=True)\n",
    "fs.ls('dev-et-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dev-et-data/greg_outputs/etasw_201401.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201402.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201403.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201404.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201405.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201406.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201407.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201408.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201409.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201410.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201411.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201412.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201501.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201502.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201503.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201504.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201505.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201506.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201507.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201508.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201509.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201510.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201511.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201512.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201601.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201602.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201603.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201604.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201605.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201606.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201607.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201608.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201609.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201610.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201611.tif',\n",
       " 'dev-et-data/greg_outputs/etasw_201612.tif']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.ls('dev-et-data/greg_outputs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
