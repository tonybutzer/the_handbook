{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes from AWS for dummies on storage\n",
    "\n",
    "Storage is the first AWS offering that Amazon offered.\n",
    "\n",
    "#### A number of AWS offerings rely on AWS storage, \n",
    "especially Simple Storage Service (S3). Understanding AWS storage services helps you better understand the operation of the AWS offerings that rely on AWS storage.\n",
    "\n",
    "S3 has over 2 trillion objects\n",
    "\n",
    "### Why 4 different serveices\n",
    "\n",
    "- scaling - need for scale\n",
    "- speed - most coporate nets are slow\n",
    "- cost - at high data vaolumes traditional approaches are expensive\n",
    "\n",
    "### Traditional Storage\n",
    "\n",
    "-note- : need to grab the slide from NEXUS on locale for storage\n",
    "\n",
    "1. NAS - looks like local - even though its on the net\n",
    "2. SAN - expensive shared storage\n",
    "\n",
    "### New storage types\n",
    "\n",
    "1. Object: Reliably stores and retrieves unstructured digital objects\n",
    "   - no update ability - example: logs\n",
    "   \n",
    "\n",
    "2. Key-value: Manages structured data\n",
    "   - scale better than traditional RDBMS systems\n",
    "   - typically store redundant copies of the data - for resilience\n",
    "   - Literally dozens of key-value storage products are available.\n",
    "   - data is structured with a single key - usually unique\n",
    "   - Retrieval is restricted to the key value.\n",
    "   - No/none/aint gonna do, cool joins and refined searches by multiple indexes\n",
    "   \n",
    "   \n",
    "### S3 use cases\n",
    "\n",
    "- dropbox\n",
    "- netflix\n",
    "- medcommons - ; complies with HIPAA!\n",
    "\n",
    "    Every S3 object has a unique URL, in this format:\n",
    "\n",
    "        http://s3.amazonaws.com/bucket/key\n",
    "\n",
    "    An actual S3 object using this format looks like this:\n",
    "\n",
    "        http://s3-us-west-1.amazonaws.com/aws4dummies/Cat+Photo.JPG\n",
    "\n",
    "\n",
    "\n",
    "so \n",
    "\n",
    "```\n",
    "tony@sleepy ~ $ cat makeS3Url.sh \n",
    "#! /bin/bash \n",
    "bucket=`aws s3 ls | cut -d' ' -f3`\n",
    "key=`aws s3 ls tbutzer-home-bucket |cut -d' ' -f7`\n",
    "wget http://s3.amazonaws.com/$bucket/$key\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "   \n",
    "\n",
    "\n",
    "Object storage offers the reliable (and highly scalable) storage of collections of bits, but imposes no structure on the bits. The structure is chosen by the user\n",
    "\n",
    "The only limitation is on object size: An S3 object is limited to 5TB. (That's large.)\n",
    "\n",
    "The **mechanism** by which this access control is enforced is, naturally enough, the Access Control List (ACL).\n",
    "\n",
    "These four types of people can access S3 objects:\n",
    "\n",
    "- **Owner**: The person who created the object; he can also read or delete the object.\n",
    "\n",
    "- **Specific users or groups**: Particular users, or groups of users, within AWS. (Access may be restricted to other members of the owner's company.)\n",
    "\n",
    "- **Authenticated users**: People who have accounts within AWS and have been successfully authenticated.\n",
    "\n",
    "- **Everyone**: Anyone on the Internet (as you may expect).\n",
    "\n",
    "Most consumer electronics and appliance manufacturers now offer their user manuals in digital format; many of them store those files in S3. \n",
    "\n",
    "\n",
    "- Create the object in preparation to use it; \n",
    "- set permissions to control access to the object; \n",
    "- allow applications and people to retrieve the object as part of an application's functionality; \n",
    "- and delete the object when the application that uses the object no longer requires it.\n",
    "\n",
    "\n",
    "Well, it depends. When an AWS virtual machine (VM) needs to access an S3 object, and the VM and the object reside in the same AWS region, Amazon imposes no charge for the network traffic that carries the object from S3 to EC2. If the VM and the object are in different regions, however (the traffic is carried over the Internet), AWS charges a few cents per gigabyte — which can be costly for very large objects or heavy use.\n",
    "\n",
    "Don't worry about this need for duplicate objects and nearly identical buckets. AWS has another, much easier solution: CloudFront (described in Chapter 9) lets you store only one copy of an object and have Amazon make it available in every region.\n",
    "\n",
    "S3 Cost\n",
    "\n",
    "S3 has a simple cost structure: You pay per gigabyte of storage used by your objects. You're also charged for API calls to S3, which don't vary by volume. Finally, you pay for the network traffic caused by the delivery of S3 objects.\n",
    "\n",
    "Storage costs start at $.095 per gigabyte per month for the first terabyte, and they trend downward as total storage increases to $.055 per gigabyte per month for more than 5000 terabytes of storage.\n",
    "\n",
    "The API call costs vary from $.01 per 1,000 requests (for PUT, COPY, POST, or LIST calls) to $.01 per 10,000 requests (for GET and all other requests). DELETE requests are free.\n",
    "\n",
    "Data transfer pricing — for transfers into or out of an AWS region — varies (as you can surmise) by volume. Transferring data in is a gift — there's no charge for inbound network traffic placing data into S3 storage. For outbound traffic, there's no charge for the first gigabyte of traffic. Then the charge becomes $.12 per gigabyte up to 10TB, with pricing lowered based on scale. The price is reduced to $.05 per gigabyte for traffic between 150TB and 500TB.\n",
    "\n",
    "Amazon also offers reduced redundancy for S3 storage, which retains fewer copies of your data — and trades reliability for cost. Reduced redundancy storage starts at $.076 per gigabyte of storage and decreases to $.037 per gigabyte at volumes higher than 5,000TB.\n",
    "\n",
    "For up-to-date pricing on S3, see http://aws.amazon.com/s3/pricing/.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Block Storage (EBS)\n",
    "\n",
    "\n",
    " A different way to say this is that an EBS volume is independent and has a lifespan separate from EC2 instances. It can be attached to any instance to provide storage for that instance, but is detached from the instance when it terminates.\n",
    "\n",
    "\n",
    "The size of an EBS volume can be configured by the user and can range from 1GB to 1TB. Volumes are associated with accounts and limited by default to 20 per account.\n",
    "\n",
    "What if your very large database needs more than 1TB of storage? You can attach multiple EBS volumes to the instance and stripe your file system across the volumes. (Stripe here refers to placing portions of a file system onto multiple volumes to increase overall read and write speed, increasing performance because all the reads and writes are spread across multiple hard drives.)\n",
    "\n",
    "\n",
    "Such a setup clearly presents a challenge. Even though Amazon retains multiple copies of the EBS volume, they're all located within the same AZ. So doesn't that conflict with the general advice to make applications more robust by letting them operate in (or be able to operate in) multiple AZs, or even across AWS regions?\n",
    "\n",
    "The short answer is yes. If your application uses EBS volumes (and, frankly, most do), it's more difficult to follow AWS best practices and operate your applications across multiple AZs. Fortunately, there's a relatively straightforward way to address this issue — by using EBS snapshots. (I tell you more on that topic later in this chapter — for now, take it on faith that the restriction that EBS volumes reside in a single AZ isn't insurmountable.)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archiving with Glacier\n",
    "\n",
    "\n",
    "NOTE\n",
    "https://www.slideshare.net/AmazonWebServices/strategic-uses-for-cost-efficient-longterm-cloud-storage-73442293\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
